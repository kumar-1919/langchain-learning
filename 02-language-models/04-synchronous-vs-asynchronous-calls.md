Great! Let's continue with:

---

## üìò 3.4 ‚Äì **Synchronous vs Asynchronous Calls in LangChain**

---

### üéØ Goal:

Understand the difference between **sync** and **async** calls in LangChain, how they affect performance, how to use them properly, and when to prefer one over the other.

---

### üìò Curriculum for 3.4

| Topic                    | Description                                     |
| ------------------------ | ----------------------------------------------- |
| ‚úÖ What is Sync vs Async? | Basic explanation with Python context           |
| ‚öôÔ∏è Function Syntax       | `invoke()` vs `ainvoke()`                       |
| üß† Technical Terms       | Coroutine, Event Loop, Blocking vs Non-blocking |
| üìÖ When to Use Which     | Use cases: sequential vs parallel calls         |
| üß™ Code Examples         | Both `invoke()` and `ainvoke()` usage           |
| ‚ö° Performance Benefit    | Async = speed via concurrency                   |
| üìÑ Summary Table         | Comparison table with pros/cons                 |

---

## ‚úÖ What Is Synchronous vs Asynchronous?

| Type             | Explanation                                                        |
| ---------------- | ------------------------------------------------------------------ |
| **Synchronous**  | Code executes one line at a time, waits for each result (blocking) |
| **Asynchronous** | Code *starts* a task, *doesn't wait*, and continues (non-blocking) |

---

## ‚öôÔ∏è Function Syntax in LangChain

All LangChain models (LLMs, Chains, Tools) support:

| Type  | Function    | Description                            |
| ----- | ----------- | -------------------------------------- |
| Sync  | `invoke()`  | Blocking call; waits for result        |
| Async | `ainvoke()` | Non-blocking call; returns a coroutine |

---

### ‚ö†Ô∏è Note:

To use `ainvoke()`:

* You must be inside an `async` function.
* Python version ‚â• 3.7 recommended.
* You need to use `await`.

---

## üß™ Code Examples

---

### ‚úÖ Synchronous Example (`invoke()`)

```python
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

llm = ChatOllama(model="llama3")

result = llm.invoke([HumanMessage(content="What is the capital of Japan?")])
print(result.content)
```

---

### ‚úÖ Asynchronous Example (`ainvoke()`)

```python
import asyncio
from langchain_community.chat_models import ChatOllama
from langchain_core.messages import HumanMessage

async def main():
    llm = ChatOllama(model="llama3")
    result = await llm.ainvoke([HumanMessage(content="Explain relativity")])
    print(result.content)

asyncio.run(main())
```

---

## üß† Technical Terms

| Term             | Meaning                                                    |
| ---------------- | ---------------------------------------------------------- |
| **Coroutine**    | A function declared with `async def`, which can be awaited |
| **Event Loop**   | Manages and schedules execution of async tasks             |
| **Blocking**     | Waits until a task is done                                 |
| **Non-blocking** | Starts task and keeps going; result comes later            |

---

## üìÖ When to Use Which?

| Scenario                        | Use                            |
| ------------------------------- | ------------------------------ |
| Single step LLM calls           | `invoke()`                     |
| Multiple parallel LLM calls     | `ainvoke()` (async)            |
| Chains that require speed-up    | `ainvoke()` inside `async def` |
| Streamlit or simple CLI tools   | `invoke()`                     |
| Web apps (e.g., FastAPI, Flask) | Prefer async (`ainvoke()`)     |

---

## ‚ö° Performance Tip

Running multiple LLMs or tools in **parallel** using `async` can reduce total time:

```python
# Async parallel call example
async def get_responses():
    task1 = llm.ainvoke([HumanMessage(content="Joke about elephants")])
    task2 = llm.ainvoke([HumanMessage(content="Joke about monkeys")])
    results = await asyncio.gather(task1, task2)
    return results
```

---

## üìÑ Summary Table

| Feature      | Synchronous               | Asynchronous                        |
| ------------ | ------------------------- | ----------------------------------- |
| Function     | `invoke()`                | `ainvoke()`                         |
| Execution    | One by one (blocking)     | Multiple in parallel (non-blocking) |
| Suitable For | Simple apps, scripts      | High-performance apps               |
| Requirements | None                      | Must use `async def` + `await`      |
| Performance  | Slower for multiple calls | Much faster for many tasks          |

---

‚úÖ That‚Äôs everything you need to know about **Synchronous vs Asynchronous LLM calls** in LangChain.

Shall we move on to the next main topic:
üìò **Section 4 ‚Äì Prompt Templates**?

Would you like the curriculum for that first?
